{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Object Detection dataset for custom classes from COCO dataset and converting it into YOLOv7 format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install `fiftyone` library to download the custom dataset from COCO\n",
    "\n",
    "- In this notebook I will be downloading datapoints from `TRAIN` split of `COCO` dataset.\n",
    "- The custom classes are `Person` and `Car`.\n",
    "- For knowing class names in the `COCO` dataset: [Click Here!](https://cocodataset.org/#detection-2020)\n",
    "- To download the dataset I will use `fiftyone` library.\n",
    "- To know more about `fiftyone`: [More about fiftyone!](https://voxel51.com/docs/fiftyone/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install fiftyone tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will download 5k instances containing either of the classes (`Person` or `Car`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as fzoo\n",
    "# To download the COCO dataset for only the 'PERSON', and 'CAR' classes\n",
    "\n",
    "train_dataset = fzoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    splits=[\"train\"],\n",
    "    label_types=[\"detections\"], # by default only detections are loaded\n",
    "    # label_field=[\"detections\"],\n",
    "    classes=[\"person\",\"car\"],\n",
    "    max_samples=5000,\n",
    "    dataset_dir=\"./dataset/\", # Save it to the dataset folder\n",
    "    only_matching=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting COCO format to YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting input_path and output_path\n",
    "input_path = Path(\"./dataset/train/\")\n",
    "output_path = Path(\"./car-person-detection/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(input_path/\"labels.json\",\"rb\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Images\n",
    "\n",
    "Reading Images from the Input directory and saving them to the Output directory with updated name in TRAIN, VAL, and TEST folder. Also saving filenames of images for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to make two changes:\n",
    "1. Use shutile.move() or shutile.copy() instead of cv2.imwrite()\n",
    "2. You have to change the line where Category_id will be written....(category_id - 1) or plus 1 according to your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3500/3500 [00:09<00:00, 379.68it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 404.33it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 377.21it/s]\n"
     ]
    }
   ],
   "source": [
    "train_filenames = None\n",
    "val_filenames = None\n",
    "test_filenames = None\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "def load_images_from_folder(folder, train_size=0.7, val_size=0.2, test_size=0.1):\n",
    "      \"\"\"\"\"\"\n",
    "      folder = Path(folder)\n",
    "      filenames = [filename.name for filename in folder.iterdir()]\n",
    "      train, validation = train_test_split(filenames, train_size=train_size,random_state=42)\n",
    "      test_size = (test_size)/(val_size+test_size)\n",
    "      validation, test = train_test_split(validation, test_size=test_size, random_state=42)\n",
    "\n",
    "      ### Moving TRAIN\n",
    "      train_filenames = train\n",
    "      count=0\n",
    "      train_images_path = output_path/\"images/train/\"\n",
    "      if not train_images_path.exists():\n",
    "            train_images_path.mkdir(parents=True)\n",
    "      for filename in tqdm(train_filenames):\n",
    "            #   img = cv2.imread(os.path.join(folder,filename))\n",
    "            #   cv2.imwrite(f\"{output_path}images/train/img{count}.jpg\", img)\n",
    "            image_name = f\"img{count}.jpg\"\n",
    "            shutil.copyfile(src = folder/filename,dst=train_images_path/image_name)\n",
    "            count+=1\n",
    "            \n",
    "      ### Moving VAL\n",
    "      val_filenames = validation\n",
    "      count=0\n",
    "      val_images_path = output_path/\"images/val/\"\n",
    "      if not val_images_path.exists():\n",
    "            val_images_path.mkdir(parents=True)\n",
    "      for filename in tqdm(val_filenames):\n",
    "            image_name = f\"img{count}.jpg\"\n",
    "            shutil.copyfile(src = folder/filename,dst=val_images_path/image_name)\n",
    "            count+=1\n",
    "\n",
    "      ### Moving TEST\n",
    "      test_filenames = test\n",
    "      count=0\n",
    "      test_images_path = output_path/\"images/test/\"\n",
    "      if not test_images_path.exists():\n",
    "            test_images_path.mkdir(parents=True)\n",
    "      for filename in tqdm(test_filenames):\n",
    "            image_name = f\"img{count}.jpg\"\n",
    "            shutil.copyfile(src = folder/filename,dst=test_images_path/image_name)\n",
    "            count+=1\n",
    "\n",
    "      return (train_filenames, val_filenames, test_filenames)\n",
    "\n",
    "train_filenames, val_filenames, test_filenames = load_images_from_folder('./dataset/train/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_ann(image_id):\n",
    "    \"\"\"\n",
    "    this method return annotation of the image from the data(json)\n",
    "    this method is dependent on global variable(data)\n",
    "    \"\"\"\n",
    "    img_ann = []\n",
    "    isFound = False\n",
    "    for ann in data['annotations']:\n",
    "        if ann['image_id'] == image_id:\n",
    "            img_ann.append(ann)\n",
    "            isFound = True\n",
    "    if isFound:\n",
    "        return img_ann\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(filename):\n",
    "  \"\"\"this method returns img file\"\"\"\n",
    "  for img in data['images']:\n",
    "    if img['file_name'] == filename:\n",
    "      return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing labels\n",
    "Applying Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': [[214.59,\n",
       "   205.04,\n",
       "   218.39,\n",
       "   203.27,\n",
       "   218.39,\n",
       "   198.97,\n",
       "   221.18,\n",
       "   195.42,\n",
       "   225.73,\n",
       "   193.9,\n",
       "   228.77,\n",
       "   192.39,\n",
       "   241.17,\n",
       "   193.4,\n",
       "   243.45,\n",
       "   212.13,\n",
       "   252.57,\n",
       "   213.65,\n",
       "   252.06,\n",
       "   199.98,\n",
       "   256.87,\n",
       "   201.25,\n",
       "   260.92,\n",
       "   204.03,\n",
       "   263.45,\n",
       "   206.56,\n",
       "   267.75,\n",
       "   223.27,\n",
       "   259.91,\n",
       "   230.86,\n",
       "   249.78,\n",
       "   256.68,\n",
       "   253.58,\n",
       "   261.24,\n",
       "   243.39,\n",
       "   262.67,\n",
       "   241.78,\n",
       "   258.9,\n",
       "   236.94,\n",
       "   258.1,\n",
       "   237.21,\n",
       "   252.45,\n",
       "   239.9,\n",
       "   252.45,\n",
       "   240.17,\n",
       "   236.05,\n",
       "   237.48,\n",
       "   224.49,\n",
       "   233.17,\n",
       "   219.92,\n",
       "   225.11,\n",
       "   219.11,\n",
       "   219.73,\n",
       "   216.42,\n",
       "   214.62,\n",
       "   210.77,\n",
       "   213.81,\n",
       "   206.47,\n",
       "   215.43,\n",
       "   205.13],\n",
       "  [247.96, 237.39, 246.89, 254.87, 248.77, 238.2, 248.77, 238.2]],\n",
       " 'area': 1698.440800000001,\n",
       " 'iscrowd': 0,\n",
       " 'image_id': 116061,\n",
       " 'bbox': [213.81, 192.39, 53.94, 70.28],\n",
       " 'category_id': 18,\n",
       " 'id': 1728}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample annotation\n",
    "data['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing labels for each split TRAIN, VAL, and TEST\n",
    "\n",
    "def process_label(filenames, output_path, class_ids):\n",
    "    count = 0\n",
    "    for filename in tqdm(filenames):\n",
    "        # Extracting Image\n",
    "        img = get_img(filename)\n",
    "        img_id = img['id']\n",
    "        img_w = img['width']\n",
    "        img_h = img['height']\n",
    "\n",
    "        # Get annotations for this image\n",
    "        img_ann = get_img_ann(img_id)\n",
    "\n",
    "        # If img_ann is not None\n",
    "        if img_ann:\n",
    "            # Opening file for current image\n",
    "            file_object = open(f\"{output_path}/img{count}.txt\", \"a\")\n",
    "        \n",
    "            for ann in img_ann:\n",
    "                current_category = ann['category_id']\n",
    "                if current_category in class_ids:\n",
    "                    current_bbox = ann['bbox']\n",
    "\n",
    "                    x = current_bbox[0]\n",
    "                    y = current_bbox[1]\n",
    "                    w = current_bbox[2]\n",
    "                    h = current_bbox[3]\n",
    "\n",
    "                    # Finding midpoints\n",
    "                    x_centre = (x + (x+w))/2\n",
    "                    y_centre = (y + (y+h))/2\n",
    "\n",
    "                    # Normalization\n",
    "                    x_centre = x_centre/img_w\n",
    "                    y_centre = y_centre/img_h\n",
    "                    w = w/img_w\n",
    "                    h = h/img_h\n",
    "\n",
    "                    # Limiting unpto fix number of decimal places\n",
    "                    x_centre = format(x_centre, '.6f')\n",
    "                    y_centre = format(y_centre, '.6f')\n",
    "                    w = format(w, '.6f')\n",
    "                    h = format(h, '.6f')\n",
    "\n",
    "                    # Writing current object\n",
    "                    # category_name = category_map[category_name] # category map from\n",
    "                    if current_category==1:\n",
    "                        current_category=0\n",
    "                    else:\n",
    "                        current_category=1\n",
    "                    file_object.write(f\"{current_category} {x_centre} {y_centre} {w} {h}\\n\")\n",
    "\n",
    "            file_object.close()\n",
    "            count+=1\n",
    "    print(f\"total_count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class_ids will be used to filter out other classes\n",
    "# because in annotation we are having all classes details\n",
    "class_ids = [1,3]# 1-person, 3-car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3500/3500 [00:57<00:00, 60.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count: 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Label Conversion for TRAIN\n",
    "train_labels_dir = Path(\"./car-person-detection/labels/train/\")\n",
    "if not train_labels_dir.exists():\n",
    "    train_labels_dir.mkdir(parents=True)\n",
    "process_label(filenames=train_filenames, output_path=\"./car-person-detection/labels/train/\",class_ids=class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:19<00:00, 50.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Label Conversion for VAL\n",
    "val_labels_dir = Path(\"./car-person-detection/labels/val/\")\n",
    "if not val_labels_dir.exists():\n",
    "    val_labels_dir.mkdir(parents=True)\n",
    "process_label(filenames=val_filenames, output_path=\"./car-person-detection/labels/val/\",class_ids=class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:08<00:00, 56.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Label Conversion for TRAIN\n",
    "test_labels_dir = Path(\"./car-person-detection/labels/test/\")\n",
    "if not test_labels_dir.exists():\n",
    "    test_labels_dir.mkdir(parents=True)\n",
    "process_label(filenames=test_filenames, output_path=\"./car-person-detection/labels/test/\",class_ids=class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading dataset to kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install kaggle --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### run the below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle/\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I have created zip file of the dataset \n",
    "- It is better to zip the dataset and then upload to Kaggle.\n",
    "- Kaggle will extract the dataset by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the dataset metadata\n",
    "# car-persob-detection is the dataset name, change it by your name,\n",
    "# otherwise will get an error of data already exist.\n",
    "!kaggle datasets init -p car-person-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = 'mdiqbalbajmi'\n",
    "os.environ['KAGGLE_KEY'] = '<kaggle_api_token>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will zip the folder, upload and kaggle will unzip it by default\n",
    "!kaggle datasets create -p car-person-detection -r zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now you are ready to go\n",
    "- Make the dataset public\n",
    "- Add it to you kaggle notebook\n",
    "- And Voila! Train your own Yolov7 models for your custom dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "819776238d7bf30a1709d096c4678fd2f08be6fd92b7239f9da4c5ad1a88ab61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
